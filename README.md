# ğŸš€ GTM Intelligence System

A sophisticated **Go-To-Market (GTM) research system** with **real-time streaming** and **multi-agent orchestration** to automatically discover, analyze, and evaluate companies based on specific research goals.

## ğŸ¯ **What It Does**

This system automatically:
- ğŸ” **Discovers companies** relevant to your research goal using Serper search API
- ğŸ“° **Extracts companies from news articles** using Playwright browser automation
- ğŸ“Š **Analyzes evidence** from multiple sources (web search, news sites, company websites)
- ğŸ§  **Evaluates quality** using AI-powered assessment with confidence scores
- ğŸ”„ **Refines strategies** based on gaps and quality metrics (iterative research)
- ğŸ“ˆ **Provides insights** with confidence scores and recommendations
- âš¡ **Real-time streaming** of agent logs and progress via Server-Sent Events
- ğŸ¨ **Modern React UI** for interactive research with configurable parameters
- ğŸ’¾ **Smart caching** with in-memory and Redis support for performance optimization

## ğŸ—ï¸ **Architecture**

### **Core Components:**
- **LangGraph Workflow**: Multi-agent orchestration with feedback loops
- **LLM Agents**: Specialized AI agents for different tasks
- **External APIs**: Serper (Google Search + News), FireCrawl (Web Scraping)
- **Browser Automation**: Playwright for automatic news site browsing
- **Real-time Streaming**: Server-Sent Events for live progress updates
- **React Frontend**: Modern UI with real-time log streaming
- **REST API**: FastAPI with streaming and synchronous endpoints

### **Agent Pipeline:**

![GTM Intelligence Workflow](gtm_graph.png)

```
Query Agent â†’ Company Aggregator (Serper + News) â†’ Multi-Source Search â†’ 
Quality Evaluator â†’ (Feedback Loop with max_iterations)
```

### **Key Features:**
- **ğŸ” Direct LLM Tool Integration**: Agents use LLM with bound Serper tools for direct extraction
- **ğŸ“° Parallel News Extraction**: Playwright-based news scraping runs alongside Serper searches
- **ğŸ”„ Iterative Research**: Configurable max_iterations for refinement cycles
- **ğŸ’¾ Smart Caching**: In-memory caching with Redis fallback for performance
- **âš¡ Real-time Streaming**: Server-Sent Events for live progress updates

## ğŸš€ **Quick Start**

### **1. Setup Environment**
```bash
# Clone the repository
git clone https://github.com/ataata107/gtm_openfunnel.git
cd OpenFunnel/gtm-langgraph

# Create virtual environment
python -m venv openfunnel
source openfunnel/bin/activate  # On Windows: openfunnel\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### **2. Configure API Keys**
Create a `.env` file in the root directory:
```env
OPENAI_API_KEY=your_openai_api_key
SERPER_API_KEY=your_serper_api_key
FIRECRAWL_API_KEY=your_firecrawl_api_key
```

### **3. Install Playwright (for news agent)**
```bash
# Install Playwright browser
playwright install chromium
```

### **4. Run the System**

#### **Option A: API Server + React Frontend**
```bash
# Terminal 1: Start API Server
source openfunnel/bin/activate
python -m uvicorn app.simple_api:app --host 0.0.0.0 --port 8001

# Terminal 2: Start React Frontend
cd frontend
npm install
npm start
```

Visit `http://localhost:3000` for the interactive UI!

#### **Option B: Direct Execution**
```bash
python main.py
```

## ğŸŒ **API Endpoints**

### **Synchronous Research**
```bash
curl -X POST "http://localhost:8001/research" \
  -H "Content-Type: application/json" \
  -d '{
    "research_goal": "Find fintech companies using AI for fraud detection",
    "search_depth": "quick",
    "max_parallel_searches": 100,
    "confidence_threshold": 0.8
  }'
```

### **Real-time Streaming Research**
```bash
curl -X POST "http://localhost:8001/research/stream" \
  -H "Content-Type: application/json" \
  -d '{
    "research_goal": "Find fintech companies using AI for fraud detection",
    "search_depth": "quick",
    "max_iterations": 1
  }'
```

### **Health Check**
```bash
curl http://localhost:8001/health
```

## ğŸ¨ **React Frontend**

### **Features:**
- âœ… **Real-time streaming** of agent logs via Server-Sent Events
- âœ… **Interactive research configuration** with all parameters
- âœ… **Live progress updates** with detailed agent logs
- âœ… **Results visualization** with confidence scores
- âœ… **Search depth controls** (quick/standard/comprehensive)
- âœ… **Max iterations configuration** (1-10 refinement cycles)
- âœ… **Streaming vs Regular mode toggle**
- âœ… **Smart caching** for improved performance

### **Usage:**
1. Navigate to `http://localhost:3000`
2. Enter your research goal
3. Select search depth (quick/standard/comprehensive)
4. Choose streaming mode for real-time logs
5. Click "ğŸš€ Start Research"
6. Watch real-time agent progress!

## ğŸ“Š **Example Output**

### **Real-time Streaming Logs:**
```
ğŸš€ Starting GTM Research (Streaming Mode)...
ğŸ“‹ Research Goal: Find fintech companies using AI for fraud detection
ğŸ” Search Depth: quick
ğŸ”„ Max Iterations: 1
â³ Connecting to API stream...

ğŸ” QUERY AGENT: Starting search strategy generation...
ğŸ¯ QUERY AGENT: Generating 10 focused search strategies
ğŸ” COMPANY AGGREGATOR: Targeting 10 results per search, 10 companies per query, 50 companies max
ğŸ“° NEWS EXTRACTOR: Using quick search depth
ğŸ” Running Serper and News extraction in parallel...
âœ… Research completed!
```

### **Final Results:**
```json
{
  "research_goal": "Find fintech companies using AI for fraud detection",
  "search_depth": "quick",
  "total_companies": 67,
  "search_strategies_generated": 10,
  "total_searches_executed": 45,
  "iterations_used": 1,
  "processing_time_ms": 45230,
  "quality_metrics": {
    "quality_score": 0.82,
    "coverage_score": 0.78,
    "missing_aspects": ["international companies"],
    "coverage_gaps": ["enterprise solutions"],
    "evidence_issues": ["outdated information"],
    "recommendations": ["focus on recent news"]
  },
  "results": [
    {
      "domain": "stripe.com",
      "confidence_score": 0.92,
      "evidence_sources": 5,
      "signals_found": 8,
      "findings": {
        "goal_achieved": true,
        "technologies": ["AI", "Machine Learning", "Fraud Detection"],
        "evidences": [
          "Stripe uses AI-powered fraud detection systems",
          "Machine learning algorithms analyze transaction patterns"
        ],
        "confidence_level": "High",
        "research_goal": "Find fintech companies using AI for fraud detection"
      }
    }
  ]
}
```

## ğŸ› ï¸ **Key Features**

### **ğŸ¤– Intelligent Agents**
- **Query Agent**: Generates diverse search strategies with quality feedback integration
- **Company Aggregator**: Extracts companies from Serper search + Playwright news scraping
- **Multi-Source Search**: Performs targeted web searches with direct LLM tool integration
- **News Extractor**: Uses Playwright to automatically browse news sites and extract companies
- **Quality Evaluator**: Analyzes research coverage and quality with detailed metrics

### **âš¡ Real-time Streaming**
- **Live Agent Logs**: See agent progress in real-time
- **Server-Sent Events**: Efficient streaming protocol
- **React Integration**: Modern UI with live updates
- **Progress Tracking**: Real-time status updates

### **ğŸ“ˆ Performance Optimization**
- **Async Processing**: Parallel API calls and LLM operations
- **Browser Automation**: Playwright for automatic news site browsing
- **Smart Caching**: In-memory caching with Redis fallback
- **Rate Limiting**: Smart handling of API limits
- **Error Recovery**: Graceful handling of failures
- **Memory Management**: Efficient processing of large datasets
- **Streaming Optimization**: Server-Sent Events for real-time updates

### **ğŸ¯ Quality Assurance**
- **Coverage Analysis**: Identifies research gaps
- **Quality Metrics**: Scores evidence reliability
- **Gap Identification**: Finds missing information
- **Strategy Refinement**: Improves search effectiveness

## ğŸ“ **Project Structure**

```
gtm-langgraph/
â”œâ”€â”€ agents/              # AI agent implementations
â”‚   â”œâ”€â”€ query_agent.py
â”‚   â”œâ”€â”€ company_aggregator_agent.py
â”‚   â”œâ”€â”€ multi_source_search_agent.py
â”‚   â”œâ”€â”€ news_search_agent.py      # Serper news API integration
â”‚   â”œâ”€â”€ news_extractor_agent.py   # Playwright browser automation
â”‚   â”œâ”€â”€ website_scraper_agent.py
â”‚   â”œâ”€â”€ evaluator_agent.py
â”‚   â””â”€â”€ quality_evaluator_agent.py
â”œâ”€â”€ graph/              # LangGraph workflow
â”‚   â”œâ”€â”€ gtm_graph.py
â”‚   â””â”€â”€ state.py
â”œâ”€â”€ app/                # API endpoints
â”‚   â””â”€â”€ simple_api.py   # FastAPI with streaming
â”œâ”€â”€ frontend/           # React application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.js
â”‚   â”‚   â””â”€â”€ components/
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ utils/              # Utility functions
â”œâ”€â”€ tests/              # Test files
â”œâ”€â”€ prompts/            # LLM prompts
â”œâ”€â”€ main.py            # Direct execution
â””â”€â”€ requirements.txt    # Dependencies
```

## ğŸ§ª **Testing**

### **Test the Core System**
```bash
python main.py
```

### **Test the API**
```bash
# Start the server
python app/simple_api.py

# Test with curl
curl -X POST "http://localhost:8001/research" \
  -H "Content-Type: application/json" \
  -d '{"research_goal": "Find AI companies", "search_depth": "quick"}'
```

### **Test the React Frontend**
```bash
cd frontend
npm start
# Visit http://localhost:3000
```

## ğŸ“ˆ **Performance Metrics**

- **Processing Speed**: Sub-30 second response times
- **Parallel Processing**: 50+ companies simultaneously
- **Search Throughput**: 65+ queries per second
- **Quality Scores**: 85%+ confidence thresholds
- **Real-time Streaming**: Live agent progress updates

## ğŸ”§ **Configuration**

### **Search Depth Options**
- **quick**: Fast search with minimal depth (~50 companies)
- **standard**: Balanced search depth and speed (~100 companies)
- **comprehensive**: Deep search with maximum coverage (~200 companies)

### **API Parameters**
- **max_parallel_searches**: Control concurrent operations (default: 100)
- **confidence_threshold**: Set quality requirements (default: 0.8)
- **max_iterations**: Limit research cycles (default: 1, range: 1-10)
- **search_depth**: Control research depth (quick/standard/comprehensive)

## ğŸš€ **Deployment**

### **Development**
```bash
# API Server
python app/simple_api.py

# React Frontend
cd frontend && npm start
```

### **Production**
```bash
# API Server
uvicorn app.simple_api:app --host 0.0.0.0 --port 8001

# React Frontend
cd frontend && npm run build
```

## ğŸ“š **Documentation**

- **[ğŸ“– Documentation Index](docs/README.md)**: Complete documentation guide
- **[ğŸš€ Quick Start Guide](docs/quick-start.md)**: Get started in 5 minutes
- **[ğŸŒ API Reference](docs/api/rest-api.md)**: Complete REST API documentation
- **[ğŸ—ï¸ Architecture Guide](docs/architecture.md)**: System design and workflow

## ğŸ¤ **Contributing**

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests to the `tests/` folder
5. Submit a pull request

## ğŸ“„ **License**

This project is licensed under the MIT License - see the LICENSE file for details.

---

**Built with â¤ï¸ using LangGraph, LangChain, OpenAI, FastAPI, React, and Playwright**

## ğŸ†• **Recent Updates**

### **v1.0.0 (Aug 2025)**
- âœ… **Max Iterations Parameter**: Configurable research refinement cycles (1-10)
- âœ… **Enhanced Caching**: In-memory caching with Redis fallback
- âœ… **Parallel News Extraction**: Playwright-based news scraping alongside Serper searches
- âœ… **Direct LLM Tool Integration**: Agents use bound Serper tools for direct extraction
- âœ… **Improved Streaming**: Server-Sent Events with proper JSON buffering
- âœ… **Comprehensive Documentation**: Complete docs structure with examples
- âœ… **Performance Optimization**: Reduced LLM invocation times and memory usage 
